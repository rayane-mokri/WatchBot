{
    "MachineLearning": {
        "2023-08-10": [
            {
                "tag": "Discussion",
                "title": "[D] I\u2019m losing my voice due to illness, and I\u2019m looking for ML/AI solution",
                "url": "https://www.reddit.com/r/MachineLearning/comments/15lmvmc/d_im_losing_my_voice_due_to_illness_and_im/",
                "text": "Hey all, like the title says, I\u2019m losing my voice due to an illness (Parkinson\u2019s disease), and I would like to create an AI voice using recordings from 10 years ago. I used to be a prolific podcaster, and I have about 50 episodes of podcasts that I can use as input. Is this possible? What service or software can I use? My voice is beyond repair since Parkinson\u2019s is a progressive disease. An AI voice would allow me to work and would open up new doors for me. Thank you!",
                "link": "https://www.reddit.com/r/MachineLearning/comments/15lmvmc/d_im_losing_my_voice_due_to_illness_and_im/",
                "date": "2023-08-10"
            },
            {
                "tag": "Discussion",
                "title": "[D] Nvidia GPU shortage is \u2018top gossip\u2019 of Silicon Valley",
                "url": "https://venturebeat.com/ai/nvidia-gpu-shortage-is-top-gossip-of-silicon-valley/",
                "text": "",
                "link": "https://www.reddit.com/r/MachineLearning/comments/15iz6v7/d_nvidia_gpu_shortage_is_top_gossip_of_silicon/",
                "date": "2023-08-10"
            },
            {
                "tag": "Project",
                "title": "[P] Looking for perspectives: Pdf parsing meets PRODUCTION",
                "url": "https://www.reddit.com/r/MachineLearning/comments/15klgt9/p_looking_for_perspectives_pdf_parsing_meets/",
                "text": "# Hi folks.\n\nI am sure you know the running gags around \u201cthin OpenAI wrapper\u201d products. Instead of more toy products, I am doing an experiment with some \u201cAI engineering\u201d to come up with a solution that\u2019s closer to being usable in actual production cases.\n\nMy background is in project management and data engineering, and I\u2019ve built large systems for big companies and worked as a consultant in the space.\n\nI\u2019ve seen enough crappy data pipelines for a lifetime.\n\nHence.\n\nI want to do something different: A thin AI wrapper is not sufficient for having reliable data pipelines that use OpenAI for schema management and inference\n\nSo this leaves me with the following doubts:\n\n&amp;#x200B;\n\n1. How to scale code horizontally and vertically? Using third-party solutions? SNS/SQS/Kafka?\n2. How to log and trace? Langsmith? Custom solutions?\n3. How to extend reliably with my own data, and make it stateful?\n\n## Looking for your perspective\n\n&amp;#x200B;\n\n* What do you think about the state of data engineering, MLOps, and infrastructure in AI companies?\n* What do you think about how to scale properly the systems and prepare them for the future?\n* In this code [here](https://github.com/topoteretes/PromethAI-Backend/tree/main/examples/level_1), I do process some PDFs as a simple pipeline, what approaches do you think could be better?\n\n## My current thinking and the state of the project\n\n&amp;#x200B;\n\n* I should create a formal scale of usability. I am looking for your input here.\n* *I should improve model consistency, extends the model with custom domain knowledge, and  make an early attempt to build simple user agents in the domain*\n* What I have is a schema inference, contracting basics, and a way to structure unstructured data\n* I\u2019m about to create a memory component that manages the data stored in vector dbs, as a DWH for AI\n* If I bring this use case that was not something available easily to the public before, how best do it?\n\nLinks:\n\nIf you like my project, please give it a star :)\n\n[my git repo ](https://github.com/topoteretes/PromethAI-Backend)",
                "link": "https://www.reddit.com/r/MachineLearning/comments/15klgt9/p_looking_for_perspectives_pdf_parsing_meets/",
                "date": "2023-08-10"
            },
            {
                "tag": "Project",
                "title": "[P] New library: dlt auto structures data and loads it with schema evolution in a declarative way.",
                "url": "https://www.reddit.com/r/MachineLearning/comments/15kbnsc/p_new_library_dlt_auto_structures_data_and_loads/",
                "text": "## Hey folks, \n\nFor the past 2 years I've been working on a library to automate the most tedious part of my own work - data loading, normalisation, typing, schema creation, retries, schema inference, evolution &amp; ddl generation, self deployment.. Basically, as you build better and better pipelines you will want more and more, and dlt supports those options.\n\nThe value proposition of this library is to automate the tedious work you do, so you can focus on better things.  \n\n\n## What's special about dlt?\n\nIn the easiest form, you shoot response.json() json at a function and it auto manages the typing normalisation and loading, kind of like a pandas df.to\\_sql() but with auto schema inference, versioning and evolution. It supports loading to files, databases, and soon table formats and vector dbs.\n\nIn its most complex form, you can do almost anything you can want, from memory management, microbatching, multithreading, extraction DAGs, 1 line Airflow/git actions deployment, dbt runner, streamlit app for data discovery, sql client, atomic state dictionaries, etc.\n\nThe library is in use with early adopters, and we are now working on expanding our feature set to accommodate the larger community. We are adding Athena + Iceberg and Weaviate vector dbs next.\n\n## Free forever\nThe library is open source and will forever be open source. We will not gate any features for the sake of monetisation - instead we will take a more kafka/confluent approach where the eventual paid offering would be supportive not competing.\n\n## Call for Feedback!\nFeedback is very welcome and so are requests for features or destinations.\n\nI would particularly love to hear from you: What destinations are you looking for from such a tool? And what use cases do you usually have? I'm a data engineer so my knowledge is more around loading external sources to a common space.\n\n## Links\n[Colab demos: Load to duckdb with schema evolution](https://dlthub.com/docs/getting-started/try-in-colab)  \n[Docs](https://dlthub.com/docs/intro)\n[main page](https://dlthub.com/)  \n\n\nThank you in advance for your feedback!",
                "link": "https://www.reddit.com/r/MachineLearning/comments/15kbnsc/p_new_library_dlt_auto_structures_data_and_loads/",
                "date": "2023-08-10"
            },
            {
                "tag": "Project",
                "title": "[Project] Making AMD GPUs competitive for LLM inference",
                "url": "https://www.reddit.com/r/MachineLearning/comments/15ml8n0/project_making_amd_gpus_competitive_for_llm/",
                "text": "There have been many LLM inference solutions since the bloom of open-source LLMs. Most of the performant inference solutions are based on CUDA and optimized for NVIDIA GPUs. In the meantime, with the high demand for compute availability, it is useful to bring support to a broader class of hardware accelerators. AMD is one potential candidate.\n\nWe build a project that makes it possible to compile LLMs and deploy them on AMD GPUs using ROCm and get competitive performance. More specifically, AMD Radeon\u2122 RX 7900 XTX gives 80% of the speed of NVIDIA\u00ae GeForce RTX\u2122 4090 and 94% of the speed of NVIDIA\u00ae GeForce RTX\u2122 3090Ti for single batch Llama2-7B/13B 4bit inference. Besides ROCm, our Vulkan support allows us to generalize LLM deployment to other AMD devices, for example, a SteamDeck with an AMD APU.\n\n\\- Github: [https://github.com/mlc-ai/mlc-llm/](https://github.com/mlc-ai/mlc-llm/)  \n\\- Blogpost describing the techniques: [https://blog.mlc.ai/2023/08/09/Making-AMD-GPUs-competitive-for-LLM-inference](https://blog.mlc.ai/2023/08/09/Making-AMD-GPUs-competitive-for-LLM-inference)\n\n&amp;#x200B;\n\n&amp;#x200B;",
                "link": "https://www.reddit.com/r/MachineLearning/comments/15ml8n0/project_making_amd_gpus_competitive_for_llm/",
                "date": "2023-08-10"
            }
        ]
    },
    "coding": {
        "2023-08-10": [
            {
                "tag": null,
                "title": "Stackoverflow has so many unhelpful people",
                "url": "https://stackoverflow.com/questions/15570994/stack-two-td-over-each-other",
                "text": "Pretty much every post I look through will have at least one nerd that didn\u2019t read the complete question and instantly spews out that there is no \u201cproper\u201d solution to that question.\n\nAlthough six other people could come up with workarounds, suggestions or helpful explanations of why something wouldn\u2019t have a solution.\n\nIt feels toxic and frankly stupid. Your answer doesn\u2019t contribute anything to the knowledge of others and it\u2019s honestly better to just not leave a comment at that point. So in case there are any nerds here reading this:\n\nIf your answer to someone\u2019s question is one sentence long and not solving their problem then don\u2019t bother commenting. People will know there is no solution too if none are given.\n\nThe link is an example wasn\u2019t planning on calling anyone specific out till I noticed a link was mandatory to post.",
                "link": "https://www.reddit.com/r/coding/comments/15kfwb5/stackoverflow_has_so_many_unhelpful_people/",
                "date": "2023-08-10"
            },
            {
                "tag": null,
                "title": "Open source \u2018protestware\u2019 harms Open Source",
                "url": "https://opensource.org/blog/open-source-protestware-harms-open-source",
                "text": "",
                "link": "https://www.reddit.com/r/coding/comments/15laf1w/open_source_protestware_harms_open_source/",
                "date": "2023-08-10"
            },
            {
                "tag": null,
                "title": "State Of Npm 2023: Top Old And New Packages",
                "url": "https://blog.sandworm.dev/state-of-npm-2023-top-old-and-new-packages",
                "text": "",
                "link": "https://www.reddit.com/r/coding/comments/15iuj2m/state_of_npm_2023_top_old_and_new_packages/",
                "date": "2023-08-10"
            },
            {
                "tag": null,
                "title": "Beware of teammates who refactor code based on personal taste without proper documentation or completeness. Sounds familiar.",
                "url": "https://digma.ai/blog/coding-horrors-tales-of-codebase-complexity/",
                "text": "",
                "link": "https://www.reddit.com/r/coding/comments/15leqxg/beware_of_teammates_who_refactor_code_based_on/",
                "date": "2023-08-10"
            },
            {
                "tag": null,
                "title": "LZ77 Is All You Need? Why Gzip + KNN Works for Text Classification",
                "url": "https://codeconfessions.substack.com/p/lz77-is-all-you-need",
                "text": "",
                "link": "https://www.reddit.com/r/coding/comments/15hypi8/lz77_is_all_you_need_why_gzip_knn_works_for_text/",
                "date": "2023-08-10"
            }
        ]
    },
    "python": {
        "2023-08-10": [
            {
                "tag": "News",
                "title": "Polars is starting a company",
                "url": "https://www.reddit.com/r/Python/comments/15h05rm/polars_is_starting_a_company/",
                "text": "I am very happy to share this news. 3 years ago I made a post to the python subreddit, introducing Polars. Back then I wanted to start from scratch and explore what a DataFrame library should be. I never would have thought I would be making this post now. :)\n\nRead our company announcement here: [https://www.pola.rs/posts/company-announcement/](https://www.pola.rs/posts/company-announcement/)\n\n&amp;#x200B;",
                "link": "https://www.reddit.com/r/Python/comments/15h05rm/polars_is_starting_a_company/",
                "date": "2023-08-10"
            },
            {
                "tag": "Tutorial",
                "title": "Python Tutorial: How to create an address cleaner with ChatGPT API and Python - Beginner Friendly",
                "url": "https://www.reddit.com/r/Python/comments/15hm5ji/python_tutorial_how_to_create_an_address_cleaner/",
                "text": "Tutorial link: [https://youtu.be/3wivIUrC7\\_Q](https://youtu.be/3wivIUrC7_Q)\n\nHey everyone! You've been incredibly supportive of my previous tutorials, so I'm excited to share a new one with you all! I finally cracked and have made a ChatGPT API tutorial. I wanted to keep things practical, it's the best way to learn. In this one you will learn how to create an address cleaner with the ChatGPT API.\n\nGoing from this input:  \n{\"address\":\"341 dandenong rd malven es vic\"} \n\nTo this output:  \n{'street\\_number': '341',  'street\\_name': 'Dandenong Rd',  'city': 'Malvern East',  'state': 'Victoria',  'postcode': '3145',  'country': 'Australia'}  \n\n\nFeedback always welcome!",
                "link": "https://www.reddit.com/r/Python/comments/15hm5ji/python_tutorial_how_to_create_an_address_cleaner/",
                "date": "2023-08-10"
            },
            {
                "tag": "Intermediate Showcase",
                "title": "Leaky Ledger, a fake bank built with Django",
                "url": "https://www.reddit.com/r/Python/comments/15i3quv/leaky_ledger_a_fake_bank_built_with_django/",
                "text": "Hi folks,\n\nI  built a bank app with Django that's meant to be hacked.   The Leaky  Ledger Bank has a signup process, accounts, and transfers, just like  you'd expect with an actual bank, but there are some pretty glaring  vulnerabilities waiting to be found.  I wrote the app hoping it would be  a fun way to explore web security in a hands-on fashion.\n\nOne disclaimer:  There are no XSS (cross-site JS scripting) vulnerabilities.\n\n[Become a Leaky Ledger banking customer.](https://ingenious-darwin.circumeo.dev/)\n\nI've also written a [guide to the vulnerabilities](https://circumeo.io/blog/entry/hacking-the-leaky-ledger-bank/) that exist so far.  You can also look at the [Django app code](https://github.com/zchtodd/leaky_ledger)  itself if you like.  Be aware that the guide and the GitHub repo are  basically spoilers.  If folks find this concept fun I'll elaborate on it  and add some more subtle problems to the bank.\n\nHappy hacking!",
                "link": "https://www.reddit.com/r/Python/comments/15i3quv/leaky_ledger_a_fake_bank_built_with_django/",
                "date": "2023-08-10"
            },
            {
                "tag": "Intermediate Showcase",
                "title": "I built ChatGPT into a rotary phone and made it sound German",
                "url": "https://www.reddit.com/r/Python/comments/15ivqii/i_built_chatgpt_into_a_rotary_phone_and_made_it/",
                "text": "Built a SIP server, a RTP sender and receiver and several HTTP clients from scratch so that the core library has no dependencies besides Python built-ins.\n\nCriticism of the code is welcome.\n\nOh, rage bait opinion: Python \"threading\" sucks ass.\n\nSource code: https://github.com/tcz/rotary-gpt\n\nYouTube video: https://youtu.be/y9bsL0o6I-A",
                "link": "https://www.reddit.com/r/Python/comments/15ivqii/i_built_chatgpt_into_a_rotary_phone_and_made_it/",
                "date": "2023-08-10"
            },
            {
                "tag": "Tutorial",
                "title": "My own Duolingo without overengineering",
                "url": "https://www.reddit.com/r/Python/comments/15mabz1/my_own_duolingo_without_overengineering/",
                "text": "Hi, my name is Mikhail Emelyanov, I\u2019m a Python programmer and I would like to show you my pet project \u2014 Flywheel, a micro-platform for learning foreign languages, a mixture of Duolingo and Anki, an application that can teach you to properly write in Spanish (or any other language you\u2019re studying). Flywheel\u2019s source code is available on [GitHub](https://github.com/amaargiru/flywheel).\n\n&amp;#x200B;\n\nhttps://preview.redd.it/6vupnx6x02hb1.png?width=946&amp;format=png&amp;auto=webp&amp;s=bc7193033427b40b644c344ea2cb0d69ec98cd63\n\nAs you may know, generalized knowledge of a foreign language can be broken down into four relatively independent components: reading, writing, listening, and speaking. Unfortunately, training one of these abilities has no direct effect on the other components, so, for example, by developing our reading skills, the effect on our writing skills is quite indirect. Flywheel is a \u2018sharpener\u2019 specifically for **written Spanish**.\n\nIf you\u2019ve ever used Duolingo, you should have some idea of the format in which you\u2019ll be studying. The formula is simple: here\u2019s a phrase, translate it into the other language; the app will remember the last time you translated a phrase and how successful you were at it; and depending on the accuracy of your answer, it will determine when you should do the same phrase again. In my opinion, Duolingo and its approach are brilliant. However... There are certain aspects that somewhat spoil the learning experience, and Flywheel was specifically designed to address them.\n\n## Wish List\n\nFirst and most importantly, I want all translation assignments to be English to Spanish only. I only want to see English phrases that I need to translate into Spanish. I don\u2019t want to translate from Spanish to English. I\u2019m not studying to be a translator; I want to learn a foreign language! And in my opinion, the way to do that is to not write anything in English at all while I\u2019m studying. There\u2019s a little lifehack for Duolingo \u2014 you can switch from learning Spanish for English speakers to learning *English for Spanish speakers* (this, in part, explains the large number of students in this course) so that the course will contain more English-to-Spanish assignments, although the amount of Spanish-to-English translations will still be very large. Whereas I want 100 % of the lesson time to be written in Spanish!\n\nSecond, I\u2019m an adult, and I don\u2019t need the studying process to be gamified at all. All those little people cheerfully winking, encouraging and advising me is one giant, irrelevant and annoying pain. There are even browser extensions that try to cut out all of these unnecessary functions, reducing the website\u2019s visuals to the necessary level of minimalism.\n\nThird, I\u2019m an adult (yes, I\u2019m repeating myself) and sometimes I don\u2019t have the time for a full-sized lesson. While Duolingo has fairly short ones, the breakdown of the learning process into set lessons containing an XX amount of questions is primarily convenient for the learning platform, not the learner. I want to be able to repeat not twenty phrases, but, say, five or three, or even one. I want to be able to interrupt the studying process at any moment without losing progress! After all, I sometimes am only able to practice on rare breaks of undetermined duration between my main activities over tea and cookies, or during breaks between spending time with the kids. If I have only a literal spare minute, I want to do a couple of sets and maintain my progress.\n\nFourth, I want to be able to add new phrases at any stage of my study! After hearing or reading something new, useful or just interesting, I want to add the phrase to the list, letting the app ensure that this phrase will remain in my memory forever.\n\nFifth, but also no less important consideration \u2014 I want the program to indicate the wrong parts of the translation. Sometimes the entered text contains small mistakes or typos, catching which is difficult with a naked eye. I want the program to show the difference between my translation and the correct version, so that I can focus on learning Spanish, and not on the game of finding the wrong letter in a long phrase in a foreign language.\n\nThis is my wish list \u2014 I want Duolingo, but only with English-to-Spanish tasks, without gamification, saving progress after each task, with the ability to add new phrases and with the visualization of the errors made, even minor ones.\n\nI think that\u2019s where the preface can end and we can get to the heart of the matter. If you simply want to start learning Spanish, go to the next section, \u2018Usage.\u2019 If you want to see the app\u2019s inner workings, go to the \u2018How It Works\u2019 section (near the end of the article).\n\n## Usage\n\nUsing Flywheel is extremely simple. At the start, you have just one file, phrases.txt (the file that comes with the application contains about two thousand phrases). Inside are many pairs of phrases, separated with a double vertical line, e.g.:\n\n*I love you || Te quiero*\n\nIf the English phrase can be correctly translated into several different Spanish phrases, a single vertical line is used to separate them:\n\n*I know || Lo se | Ya se | Yo s\u00e9*\n\nIf there are two English phrases that can also have multiple equivalent translations, a single vertical line is also used to separate them.\n\nOf course, you can and should add **your own phrase pairs** to phrases.txt. This is the essence of Flywheel \u2014 you don\u2019t have to memorize the dictionary, it\u2019s just a template. Adjust the content of the lessons to suit your level of proficiency; move the phrase pairs you find most useful higher up in the dictionary; add pairs related to your job. Needless to say, the shell doesn\u2019t care what language you\u2019re learning. If you wish to learn French, bien accueillir! Want to learn Aleutian? No problem. Need to learn Aleutian as a native French speaker? Easy as pie!\n\nPlease don\u2019t add single words to the dictionary! Sure, technically it\u2019s possible, but it\u2019s not particularly worthwhile from the perspective of language learning efficiency. Try adding phrases specifically, and if you want to add a specific new word to your vernacular it\u2019s better to pick up a phrase which uses it in a specific context. This way you\u2019ll not only remember the word better, but you\u2019ll more easily move it from the passive phase to the active phase, as you won\u2019t simply recognize it in a text or in speech, but will actually start applying it in writing and in speaking.\n\nNext, simply run flywheel.py. Two more files will be added to your application folder \u2014 repetitions.json (this will record your progress and memorization of all completed phrase pairs) and user\\_statistics.txt (this will record the total number of exercises you have completed and will generate a general list of words you have managed to learn).\n\n## How It Works\n\nIf you are a beginner Python developer and want to try your hand at something simple but not useless, give Flywheel a whirl. Maybe you\u2019ll be able to add some hot new features to it, and improve your Spanish while debugging it as well. Naturally, most of the methods used in the application don\u2019t need a lot of describing, so I\u2019ll focus only on the general approach and the key functions that are directly related to the analysis of user progress.\n\nRecently I have been practicing the following method: I write a template main as if all of the application\u2019s methods have already been developed and I just need to call them. This gives you sort of a bird\u2019s-eye view of the code (even if it\u2019s more like a penguin\u2019s rather than an eagle\u2019s :) and a rough estimate of the level of effort required. This is what I ended up with:\n\n    phrases_file_name = \"phrases.txt\"\n    repetitions_file_name = \"repetitions.json\"\n    \n    if __name__ == \"__main__\":\n        phrases_file_path = find_or_create_file(phrases_file_name)\n        repetitions_file_path = find_or_create_file(repetitions_file_name)\n    \n        phrases = read_phrases(phrases_file_path)\n        repetitions = read_repetitions(repetitions_file_path)\n        can_work, error_message = data_assessment(phrases, repetitions)\n    \n        if can_work:\n            message = merge(repetitions, phrases)\n            print(message)\n            while True:\n                current_phrase = determine_current_phrase(repetitions)\n                user_result = user_session(current_phrase)\n                update_repetitions(repetitions, current_phrase, user_result)\n                save_repetitions(repetitions_file_path, repetitions)\n        else:\n            print(error_message)\n            exit()\n\nThe operating logic is roughly thus:\n\n\u2022 we look for phrases.txt in the project directories (lots of phrase pairs separated by a dual vertical line, see the \u2018Usage\u2019 section for details); if we can\u2019t find it, we create a blank file for future editing by the user;\n\n\u2022 similarly, we look for repetitions.json (progress records and memorization degrees of all complete phrase pairs); if not found, we create an empty file;\n\n\u2022 we create data structures from the information taken from phrases.txt and repetitions.json, and then evaluate whether we can work with given combination. If phrases.txt is not empty, then okay, we can convert phrase pairs to our internal format and transfer that information to repetitions.json. If repetitions.json is not empty, then also okay, we can work with the information we\u2019ve already accumulated. Both phrases.txt and repetitions.json being empty is not okay, we have nowhere to draw the information we need to work, so we complain about this fact to the user, let them create phrases.txt with at least some minimal content;\n\n\u2022 during the loop, we feed a new task to the user, picking the most relevant phrase we need at the moment from the phrase dictionary. If there are phrases that require repetition, we pick them first; if all completed tasks don\u2019t require a refresher right now, we start mixing in new phrases.\n\n\u2022 after each task, we update the data in repetitions.json and the user\u2019s statistics, regardless of the quality of the answer.\n\nIn the process of writing the code, I divided all the functionality into data\\_level (sort of the essence of the language practice itself), system\\_level (functionality that depends on the operating system) and ui\\_level (methods that determine how to interact with the user), also adding a statistics file showing the total number of attempts made by the user and containing all the Spanish and English words that they learned. The final version turned out to be about the same as the original blueprint, if only a little more spread out:\n\n    from data_level import DataOperations as dop\n    from system_level import FileOperations as fop\n    from ui_level import UiOperations as uop\n    \n    phrases_file_name: str = 'phrases.txt'\n    repetitions_file_name: str = 'repetitions.json'\n    statistics_file_name: str = 'user_statistics.txt'\n    \n    if __name__ == '__main__':\n        phrases_file_path = fop.find_or_create_file(phrases_file_name)\n        repetitions_file_path = fop.find_or_create_file(repetitions_file_name)\n        user_statistics_file_path = fop.find_or_create_file(statistics_file_name)\n    \n        phrases: dict = fop.read_phrases(phrases_file_path)\n        repetitions: dict = fop.read_json_from_file(repetitions_file_path)\n        can_work, assesment_error_message = dop.data_assessment(phrases, repetitions)\n    \n        statistics: dict = fop.read_json_from_file(user_statistics_file_path)\n    \n        if can_work:\n            is_merged, merge_message = dop.merge(phrases, repetitions)\n            print(merge_message)\n            if is_merged:\n                fop.save_json_to_file(repetitions_file_path, repetitions)\n    \n            while True:\n                current_phrase: str = dop.determine_next_phrase(repetitions)\n                user_result, best_translation = uop.user_session(current_phrase, repetitions[current_phrase])\n    \n                dop.update_repetitions(repetitions, current_phrase, user_result)\n                fop.save_json_to_file(repetitions_file_path, repetitions)\n    \n                statistics = dop.update_statistics(statistics, current_phrase, best_translation)\n                fop.save_json_to_file(statistics_file_name, statistics)\n        else:\n            print(assesment_error_message)\n            exit()\n\nFirst we need to determine whether the user answered the given question correctly, allowing for the possible existence of several correct versions of the translation.\n\n    # import jellyfish\n    \n    def find_max_string_similarity(user_input: str, translations: str | List[str]) -&gt; (float, str):\n        \"\"\"Compares user_input against each string in translations\"\"\"\n        max_distance: float = 0\n    \n        if isinstance(translations, str):\n            translations = [translations]\n        best_translation: str = translations[0]\n    \n        # Cleanup and 'compactify' user input ('I   don't know!!!\ud83d\ude00' -&gt; 'i dont know')\n        user_input = DataOperations._compact(DataOperations._cleanup_user_input(user_input).lower())\n    \n        # 'Compactify' translations\n        translations = [(t, DataOperations._compact(t.lower())) for t in translations]\n    \n        for translation, compact_translation in translations:\n            current_distance = jellyfish.jaro_distance(user_input, compact_translation)\n    \n            if current_distance &gt; max_distance:\n                max_distance = current_distance\n                best_translation = translation\n    \n        return max_distance, best_translation\n    \n    def _compact(input_string: str) -&gt; str:\n        \"\"\"Restrict use of all special characters and allow letters and numbers only\"\"\"\n        return ''.join(ch for ch in input_string if ch.isalnum() or ch == ' ')\n\nInside the husk engaged in data transfer, you can see the Jaro distance calculation:\n\n    current_distance = jellyfish.jaro_distance()\n\nAccordingly, there is an estimate of the accuracy of the user\u2019s answer:\n\n    level_excellent: float = 0.99\n    level_good: float = 0.97\n    level_mediocre: float = 0.65\n\nCome to think of it, maybe the Levenshtein distance would be more appropriate here?\n\nBy the way, try turning this:\n\n    user_input = DataOperations._compact(DataOperations._cleanup_user_input(user_input).lower())\n\ninto something like this (I don't mean dropping DataOperations, but rather arranging a pipe for methods like string):\n\n    user_input = user_input.lower().cleanup().compact()\n\nUnfortunately, adding your own methods to those provided by Python requires either using subclasses or reinventing something like forbiddenfruit (bit dead already) / fishhook (still a little raw). Meanwhile, C# provides this feature out of the box, curses!\n\nThe interval repetition algorithm, which, depending on the quality of the answer, decides when a completed phrase will be offered to the user next time, is based on [SuperMemo-2](https://en.wikipedia.org/wiki/SuperMemo#Description_of_SM-2_algorithm):\n\n    def _supermemo2(repetition: dict, user_result: float) -&gt; dict:\n        \"\"\"Update next attempt time based on user result\"\"\"\n        if user_result &gt;= DataOperations.level_good:  # Correct response\n            if repetition['repetition_number'] == 0:  # + 1 day\n                repetition['time_to_repeat'] = (datetime.now() + timedelta(days=1)).strftime(datetime_format)\n            elif repetition['repetition_number'] == 1:  # + 6 days\n                repetition['time_to_repeat'] = (datetime.now() + timedelta(days=6)).strftime(datetime_format)\n            else:  # + (6 * easiness_factor) days\n                repetition['time_to_repeat'] = (datetime.now()\n                                                + timedelta(days=6 * repetition['easiness_factor'])).strftime(datetime_format)\n            repetition['repetition_number'] += 1\n        else:  # Incorrect response\n            repetition['repetition_number'] = 0\n    \n        repetition['easiness_factor'] = repetition['easiness_factor'] + (\n                0.1 - (5 - 5 * user_result) * (0.08 + (5 - 5 * user_result) * 0.02))\n        repetition['easiness_factor'] = max(repetition['easiness_factor'], 1.3)\n    \n        return repetition\n\nThe SuperMemo family of algorithms has more recent implementations, up to SuperMemo-18. You can move over to using them, repetitions.json stores the last few user attempts specifically for this purpose.\n\n    max_attempts_len: int = 10  # Limit for 'Attempts' list\n\nWhile you\u2019re at it, try to figure out why, despite the fact that SuperMemo-18 exists, SuperMemo-2 is still actively used, and even the most adventurous developers don\u2019t venture beyond SuperMemo-5 or, at most, a simplified SuperMemo-8. Have a look at [A Trainable Spaced Repetition Model for Language Learning](https://github.com/duolingo/halflife-regression/blob/master/settles.acl16.pdf), an algorithm published by the developers of Duolingo, which attempts to address the shortcomings of previous approaches. Try to replicate Duolingo\u2019s key functionality, it\u2019s quite feasible.\n\nNext comes the saving of the results; I think there\u2019s no need to dwell on the implementation of this function.\n\nNow that the user\u2019s answer has been weighed and accounted for, we need to show the student not only the correct option, but also the specifics that will help them identify the mistakes. To do this, we will first form a data structure containing information on the difference between the desired and the actual result.\n\n    # from dataclasses import dataclass\n    # from difflib import SequenceMatcher\n    \n    def find_user_mistakes(user_input: str, reference: str) -&gt; list:\n        \"\"\"Dig for user errors and typos\"\"\"\n    \n        @dataclass\n        class ComplexPhrase:\n            phrase_without_punctuation: List[str]\n            transformation_matrix: List[int]\n    \n        user_input = DataOperations._cleanup_user_input(user_input).lower()\n        reference = reference.lower()\n        correction_map: list[bool] = [True] * len(reference)\n    \n        complex_reference: ComplexPhrase = ComplexPhrase(phrase_without_punctuation=[], transformation_matrix=[])\n    \n        # 'Minify' reference phrase and remember transformation shifts\n        for i, ch in enumerate(reference):\n            if ch.isalnum() or ch == ' ':\n                complex_reference.phrase_without_punctuation.append(ch)\n                complex_reference.transformation_matrix.append(i)\n    \n        minified_reference: str = ''.join(complex_reference.phrase_without_punctuation)\n        corr_map: list[bool] = [False] * len(minified_reference)\n    \n        # Compare cleaned user input and 'minified' reference\n        seq = SequenceMatcher(lambda ch: not (ch.isalnum() or ch == ' '), user_input, minified_reference)\n        blocks = seq.get_matching_blocks()\n        blocks = blocks[:-1]  # Last element is a dummy\n    \n        for _, i, n in blocks:\n            if n &gt;= 3:  # Don't show to the user too short groups of correct letters, perhaps he entered a completely different phrase\n                for x in range(i, i + n):\n                    corr_map[x] = True\n    \n        # 'Unminify' reference phrase and restore transformation shifts\n        for i, corr in enumerate(corr_map):\n            if corr is False:\n                correction_map[complex_reference.transformation_matrix[i]] = False\n    \n        return correction_map\n\nA bit complicated? At a glance, we could have taken a shorter route by directly applying SequenceMatcher to the user\u2019s response and reference phrase, like this.\n\n    def find_user_mistakes(user_input: str, reference: str) -&gt; list:\n        \"\"\"Display of user errors\"\"\"\n        seq = SequenceMatcher(None,\n                                \"\".join(DataOperations._compact(DataOperations._cleanup_user_input(user_input).lower())),\n                                DataOperations._compact(reference.lower()))\n        blocks = seq.get_matching_blocks()\n        blocks = blocks[:-1]  # Last element is a dummy\n    \n        corr_map: list = [False] * len(reference)\n    \n        for _, i, n in blocks:\n            if n &gt;= 3:  # Don't show to the user too short groups of correct letters, perhaps he entered a completely different word\n                for x in range(i, i + n):\n                    corr_map[x] = True\n    \n        return corr_map\n\nInstead, we wrap and then unwrap some additional data structure that does not store all the characters from the source text, but remembers which characters are shifted where. What for?\n\nThe thing is, one of Duolingo\u2019s key features is that it ignores punctuation and the difference between uppercase and lowercase letters. For example, it\u2019s perfectly acceptable to type \u2018hello my name is kitty\u2019 instead of \u2018Hello! My name is Kitty,\u2019 and that\u2019s pretty cool. After all, we\u2019re primarily studying the grammar of a foreign language, having already learned the general rules of writing names and punctuation (although Spanish has its own peculiarities), and getting a fail for spelling the name Michael with a lowercase letter would certainly be a huge drawback for the whole user experience.\n\nThis is the kind of goodie I wanted to implement in Flywheel as well. That\u2019s why the reference phrase and the user\u2019s answer are first converted into plain text without punctuation and capital letters, then compared, ending with the reference phrase once again unfolded into a full response and shown to the user.\n\nNext, to clearly show the mistakes and typos to the user, we form a full-colour user output, a phrase in which the colour of the character will depend on the correctness of its spelling:\n\n    def _print_colored_diff(correction, reference) -&gt; None:\n        \"\"\"Visualisation of user errors\"\"\"\n        for i, ch in enumerate(reference):\n            if correction[i]:\n                print(Fore.GREEN + ch, end='')\n            else:\n                if ch != ' ':\n                    print(Fore.RED + ch, end='')  # Just a letter\n                else:\n                    if i - 1 &gt;= 0 and i + 1 &lt; len(reference):  # Emphasise the space between correct but sticky characters\n                        if correction[i - 1] and correction[i + 1]:\n                            print(Fore.RED + '_', end='')\n                        else:\n                            print(Fore.RED + ' ', end='')\n\nThis ends the life cycle of the question in the console application.\n\nWant something like that, but more sophisticated (because making the user quit the application using Ctrl-C is kind of gross), with a web interface, database, ORM, API, and voice prompts? Have a look in the [flywheel/Legacy](https://github.com/amaargiru/flywheel/tree/main/Legacy) folder. It contains some working code that differs from the latest micro-version described in this article by having a less consistent data\\_level (in particular, not knowing about SuperMemo, I tried to invent my own algorithm of interval repetitions), but it has all of the aforementioned goodies. Perhaps you\u2019ll hear the quiet one-handed clap calling you back to the console later... Meanwhile, you can try to make your own startup, building a potential rival to Duolingo, Cerego, Course Hero or Memrise.\n\n## Outro\n\nWell, that\u2019s about it for now. From now until the end of your current lifecycle, you can spend as much time on learning a foreign language as you like, add new phrases or add to existing translations and keep up with your progress even after minuscule efforts.\n\nHowever, keep in mind that: \n\n\u2022 first of all, miracles are not real, and you will have to spend a considerable amount of time ([approximate estimates](https://support.cambridgeenglish.org/hc/en-gb/articles/202838506-Guided-learning-hours)) to learn the language in any case;\n\n\u2022 and, secondly, as aptly noted by Ilya Frank, \u2018Language is akin to an icy hill \u2014 you have got to move fast if you want to get to the top of it,\u2019 that is, in other words, if you don\u2019t dedicate enough time to language learning, and keep to a fairly tight schedule, you will not be able to reach a new equilibrium point, and your acquired knowledge will slowly but surely fade away.\n\nIf you have any questions, feel free to leave them in the comments. As a reminder, Flywheel\u2019s source code is available on [GitHub](https://github.com/amaargiru/flywheel) and is updated and corrected whenever possible. If this rather simple but, in my opinion, very effective method of learning Spanish grabbed your attention, please create repository forks, make corrections both to code (project is written in Python and contains only about four hundred lines) and to the list of translated phrases. If you could leave a star on GitHub, that would be great.\n\nYou know what I like most about this method? After a few days of using the app, my Spanish obviously didn\u2019t improve much. However! I gained a distinct feeling of control over the process of learning a foreign language! Previously, when using Duolingo, I had this feeling of passivity, like a passenger in a bumper car welded to the base of an amusement park ride: the car would move, then suddenly jerk to the right, then make a gentle left turn... Perhaps the trajectory was fairly good, and scientifically sound, but my issue was that it didn\u2019t consider my previous knowledge and individual preferences. Now that both data and methods of their processing are in my hands, I feel that my little car is more or less obeying the steering wheel and is going in the direction I need.",
                "link": "https://www.reddit.com/r/Python/comments/15mabz1/my_own_duolingo_without_overengineering/",
                "date": "2023-08-10"
            }
        ]
    },
    "rust": {
        "2023-08-10": [
            {
                "tag": null,
                "title": "Polars is starting a company",
                "url": "https://www.reddit.com/r/rust/comments/15gzt3r/polars_is_starting_a_company/",
                "text": "It has been 3 years since I first shared polars in this subreddit. I never would have expected to be making this post, but here we are :). I am super excited about this opportunity and the cool stuff we hope to build.\n\nRead more in the official blog post: [https://www.pola.rs/posts/company-announcement/](https://www.pola.rs/posts/company-announcement/)",
                "link": "https://www.reddit.com/r/rust/comments/15gzt3r/polars_is_starting_a_company/",
                "date": "2023-08-10"
            },
            {
                "tag": "\ud83c\udf99\ufe0f discussion",
                "title": "Long term C++ dev moving to Rust, and my reasons behind the decision.",
                "url": "https://www.reddit.com/r/rust/comments/15lft59/long_term_c_dev_moving_to_rust_and_my_reasons/",
                "text": "Hello everyone,\n\nAfter using C++ for more than 10 years, I'm moving on to Rust.\n\nI'm a founder of a startup for creating High Performance Scientific code, and will be choosing Rust for the following reasons. I hope sharing my experience, will help other developers and teams to decide if Rust is good for their needs, or not.\n\nC++ has been good for me over the years, and as I learn Rust, I would need to keep using C++ for my professional work, as most of my code is already in C++, but with time, I'm definitely going to rewrite all of my code with Rust.\n\nMy decision to switch to Rust is motivated by mainly following three reasons ...\n\n&amp;#x200B;\n\n1. **Safety and correctness when working in a team :** I write High Performance Scientific code, and I want my code to be safe. I can more or less write safe code, but when working in a team, it's not possible to hire junior team members who are as good as writing safe code as senior team members. They can write safe code with guidance and experience, but it takes a lot of time to teach them. Rust's memory safety would automatically fix a lot of the bugs that can occur. Rust will also help senior team members, so they can be more productive, as they don't have to worry about writing safe code. The Rust compiler would help them along the way.\n2. **Build system and deployment :** C/C++'s build system, or lack thereof, is very painful when using third party libraries.  It is not uncommon to spend 3-4 days trying to integrate a new library with our build system, as most often the third party library depends on 3-10 other third party libraries, and it often takes a minimum of 3-4 days to just fix all compiler errors, and build the thing. Deploying the code similarly, is very painful, because we have to repeat the same process on a user's computer, and if it fails, we need to fix our own build code to support their OS/Distro/LibraryVersion etc. Linux for example. has too many distros, and supporting build/deployment to all with a  simple CMake script is often not possible. It often takes lot of time and resources to just create a single CMake script that works on all OS/Distros. From a management standpoint, this is a continuous waste of resources. Rust solves this with its single build system that works almost everywhere.  Being able to pull in third party libraries from cargo, is also a lifesaver, and would allow devs to try out different libraries, and chose one that's best for our task at hand.\n3. **Safety and correctness when using third party libraries :** I've continued to use C++ for a long time because our own code goes through a severe validation process, and we make sure that it's safe and correct. But often third party libraries have bugs, or we ourselves don't know how to safely use the library, so we cause memory leaks, or data corruption, or race conditions. This is very unique because we don't face the same problems in our own code. Kindly note that I'm not blaming third party devs, but pointing out that it's easy for us to introduce bugs when using third party libraries, because we don't know it well enough to safely use it. Rust, surprisingly, also solves this. The safety issue with third party libraries go all the way down to system driver levels, as just today while using VTK, I *possibly* found a GPU driver bug that was leaking memory. I've verified that we have a severe memory leak that was OOM'ing the OS, and freezing it, but we have to investigate more if this bug is present in our code (i.e our mistake), or as I suspect, in the GPU driver itself. I hope that as Rust is used more for system driver development, severe bugs like these can be eradicated.\n\nI could probably include a lot more, but from a high level management perspective, these points are the most important for me, and will save us a lot of time while delivering high quality software.\n\nThanks\n\n&amp;#x200B;",
                "link": "https://www.reddit.com/r/rust/comments/15lft59/long_term_c_dev_moving_to_rust_and_my_reasons/",
                "date": "2023-08-10"
            },
            {
                "tag": null,
                "title": "Stable Diffusion in Pure Rust",
                "url": "https://www.reddit.com/r/rust/comments/15jc09o/stable_diffusion_in_pure_rust/",
                "text": "After porting Whisper and Llama 2 to Rust I felt the next natural step was Stable Diffusion. Whisper and Llama are fairly elegant models so I was expecting more of the same. How I was wrong! Compared with the other two models, Stable Diffusion is a behemoth. There are layers upon layers of modules with relatively complex data flows. Oh yes, there were bugs and bugs within bugs, but after many hours of staring at and hallucinating point numbers I finally typed the most creative thing my sleep deprived mind could think of: a rainbow pony. Behold the fruit of my suffering!:\n\n[Suffering on the left and Bliss on the right](https://preview.redd.it/np60kzja0egb1.jpg?width=1360&amp;format=pjpg&amp;auto=webp&amp;s=b9fe3b61307a602e5a158401fd70ace175f9d596)\n\nNow you can have all the rainbow ponies you desire powered by Rust, just don't even try generating hands or faces lest you come face to face with uncanny valley. However, I included scripts in the project that can dump and convert fine tuned models to Rust's burn format so those of you with, ahem, particular tastes, can fulfill your desires.\n\nCheck out the GitHub page: [Gadersd/stable-diffusion-burn](https://github.com/Gadersd/stable-diffusion-burn/tree/main)\n\nIf you are interested in this project and want to see more such as Stable Diffusion XL in Rust and web assembly versions that can run in browsers consider supporting my work by buying a shirt at [https://www.bonfire.com/machine-learning/](https://www.bonfire.com/machine-learning/). The shirt image was, of course, generated by my Rust powered Stable Diffusion! I'd love to release more projects and any support will help make that happen!",
                "link": "https://www.reddit.com/r/rust/comments/15jc09o/stable_diffusion_in_pure_rust/",
                "date": "2023-08-10"
            },
            {
                "tag": null,
                "title": "Rustc updated to LLVM 17, for ~2% compile time improvements",
                "url": "https://github.com/rust-lang/rust/pull/114048",
                "text": "The Rust compiler has updated to LLVM 17, which resulted in nice compile-time wins (https://perf.rust-lang.org/compare.html?start=03a119b0b0e310d22d94399b24ed030056050f13&amp;end=443c3161dd04f4c1b656a626f9079921bee9c326&amp;stat=instructions%3Au&amp;tab=compile&amp;nonRelevant=true). It seems that code generation quality was also improved  if we are to believe the newly introduced runtime benchmarks :)\n\nThe corresponding PR is here: \nhttps://github.com/rust-lang/rust/pull/114048",
                "link": "https://www.reddit.com/r/rust/comments/15l9650/rustc_updated_to_llvm_17_for_2_compile_time/",
                "date": "2023-08-10"
            },
            {
                "tag": "\ud83d\uddde\ufe0f news",
                "title": "Ratatui is the official successor of tui-rs! (library to build rich terminal user interfaces and dashboards)",
                "url": "https://github.com/fdehau/tui-rs/commit/335f5a4563342f9a4ee19e2462059e1159dcbf25",
                "text": "",
                "link": "https://www.reddit.com/r/rust/comments/15jml7r/ratatui_is_the_official_successor_of_tuirs/",
                "date": "2023-08-10"
            }
        ]
    },
    "cpp": {
        "2023-08-10": [
            {
                "tag": null,
                "title": "What is the most difficult feature or concept in C++ , in your opinion?",
                "url": "https://www.reddit.com/r/cpp/comments/15hwq7n/what_is_the_most_difficult_feature_or_concept_in/",
                "text": "Preferably some obscure features or weird design patterns , the kind of things you wouldn't want to show a newbie because you fear you're going to scar him for life.For me , the weirdest was definitely the variadic templates. I'm implementing a scene graph traversal , and I want it to be totally generic with any functor and any argument .  \n\n\nEdit : Holy shit , I feel like I've opened  pandora's box.   \nBefore that I thought I knew at least 30% of the language , but the more I read your comments, the more I think it's rather 10% , and the 1% is what I've been taught in university .   \n",
                "link": "https://www.reddit.com/r/cpp/comments/15hwq7n/what_is_the_most_difficult_feature_or_concept_in/",
                "date": "2023-08-10"
            },
            {
                "tag": null,
                "title": "Review of proposed Boost.Async begins",
                "url": "https://www.reddit.com/r/cpp/comments/15l8xju/review_of_proposed_boostasync_begins/",
                "text": "It is my great pleasure to announce the beginning of the peer review of proposed Boost.Async, which is hoped to become the most popular way of programming C++ coroutines in future C++. The peer review shall run between Tuesday 8th August and Friday 18th August.\n\nLike many of you have found, until now there has been no good standard and easy way of writing C++ coroutine code which works easily with multiple third party codebases and foreign asynchronous design patterns. ASIO\u2019s current coroutine support is tightly coupled to ASIO, and it rejects foreign awaitables. Libunifex is dense to master and non-obvious to make work well with foreign asynchronous design patterns, not helped by a lack of documentation, a problem which also afflicts stdexec which also has a steep and dense learning curve. CppCoro is probably currently the best in class solution to the space of easy to use fire and forget C++ coroutine programming, but it isn\u2019t particularly portable and was designed long before C++ coroutine standardisation was completed.\n\nKlemens very kindly stepped up and created for us an open source ground-up reimplementation of the best ideas of hitherto proprietary commercial C++ coroutine libraries, taking in experience and feedback from multiple domain experts in the area to create an easy to use C++ coroutine support library with excellent support for foreign asynchronous design patterns. For example, if you want your coroutine to suspend while a stackful fiber runs and then resume when that fiber has done something \u2013 AND that fiber implementation is unknown to Boost.Async \u2013 this is made as easy as possible. If your C++ coroutine code wants to await on unknown foreign awaitables, that generally \u201cjust works\u201d with no added effort. This makes tying together multiple third party dependencies into a solution based on C++ coroutines much easier than until now.\n\nThe industry standard executor is ASIO, so Boost.Async uses Boost.ASIO as its base executor. To keep things simple and high performance, Boost.Async requires each pool of things it works with to execute on a single kernel thread at a time \u2013 though there can be a pool of things per kernel thread, or an ASIO strand can ensure execution never occurs on multiple kernel threads. The basic concurrency primitives of promise, generator and task are provided, with the fundamental operations of select, join and gather. Some more complex async support is supplied: Go-type channels, and async teardown. Performance is superior to both stackful coroutines and ASIO\u2019s own C++ coroutine support, and sometimes far superior.\n\nYou can read the documentation at https://klemens.dev/async/ and study or try out the code at https://github.com/klemens-morgenstern/async. \n\nAnyone with experience using C++ coroutines is welcome to contribute a review at the Boost mailing list (https://lists.boost.org/mailman/listinfo.cgi/boost), here at this Reddit page, via email to me personally, or any other mechanism where I the review manager will see it. In your review please state at the end whether you recommend acceptance, acceptance with conditions, or rejection. Please state your experience with C++ coroutines and ASIO in your review, and how many hours you spent on the review.\n\nThanks in advance for your time and reviews!\n\n\n----\n\nLikely very common question: How does this compare to Senders-Receivers and https://wg21.link/P2300 `std::execution`?\n\nSenders-Receivers are the natural abstraction over C++ coroutines, and map orthogonally onto them. P2300 aims to implement structured (preplanned) rather than adhoc (initiate as we go) concurrency, which infers lazy rather than eager awaitables. A lot of the complexity and learning curve in P2300 based code stems from these design choices, plus additional effort to manage the by-default dynamic memory allocations of lazy awaitables.\n\nBoost.Async is eager awaitable and adhoc concurrency orientated, and doesn\u2019t bother with abstracting out C++ coroutines at all, instead choosing C++ coroutines and Boost.ASIO as concrete immutable design choices. It is almost the opposite of P2300 in terms of philosophy as a result by vastly reducing the number of potential customisation points in exchange for getting users up and running quickly without having to think much about why or how. P2300 will have much more power and flexibility, but if you\u2019re happy with C++ coroutines and Boost.ASIO and don\u2019t need anything more, Boost.Async should be hard to beat.\n\nFinally eager awaitables should in the future be more runtime efficient with no extra effort than lazy awaitables because future compilers should be able to optimise out a lot of coroutine frame dynamic memory allocations. I keep saying \"in the future\" here because I know of no current compiler which is any good at this, but it is purely a QoI problem. I was one of the few voices on WG21 which championed eager over lazy awaitables because of their easy suitability for early zero overhead completion, which particularly suits file i/o as there is a high probability than an i/o will hit cache and complete without suspend-resume. Some patterns of socket i/o can similarly be more efficient with no extra effort.",
                "link": "https://www.reddit.com/r/cpp/comments/15l8xju/review_of_proposed_boostasync_begins/",
                "date": "2023-08-10"
            },
            {
                "tag": null,
                "title": "Inside STL: The string",
                "url": "https://devblogs.microsoft.com/oldnewthing/20230803-00/?p=108532",
                "text": "",
                "link": "https://www.reddit.com/r/cpp/comments/15h5sta/inside_stl_the_string/",
                "date": "2023-08-10"
            },
            {
                "tag": null,
                "title": "What's New for C++ Developers in Visual Studio 2022 17.7 - C++ Team Blog",
                "url": "https://devblogs.microsoft.com/cppblog/whats-new-for-c-developers-in-visual-studio-2022-17-7/",
                "text": "",
                "link": "https://www.reddit.com/r/cpp/comments/15lwn6l/whats_new_for_c_developers_in_visual_studio_2022/",
                "date": "2023-08-10"
            },
            {
                "tag": null,
                "title": "C++/WinRT is now in maintenance mode.",
                "url": "https://github.com/microsoft/cppwinrt/issues/1289#issuecomment-1481303844",
                "text": "",
                "link": "https://www.reddit.com/r/cpp/comments/15lk6fn/cwinrt_is_now_in_maintenance_mode/",
                "date": "2023-08-10"
            }
        ]
    },
    "unrealengine": {
        "2023-08-10": [
            {
                "tag": "Discussion",
                "title": "FRAUD ALERT FOR GAME DEVLOPERS!!",
                "url": "https://www.reddit.com/r/unrealengine/comments/15i97pt/fraud_alert_for_game_devlopers/",
                "text": "I been working for the company name \"DRIP GAMING\" and they scammed me after I did 4 months of work then denied payment. I talk about this in the linkedIN Post below  \n\nhttps://www.linkedin.com/posts/selwynr_attention-fraud-alert-part-1-many-people-activity-7093301741508567040-P0uO?utm_source=share&amp;utm_medium=member_android\n\nhttps://www.linkedin.com/posts/selwynr_gamedevelopment-gameindustry-dripgaming-activity-7093324670799650817-FT_k?utm_source=share&amp;utm_medium=member_android",
                "link": "https://www.reddit.com/r/unrealengine/comments/15i97pt/fraud_alert_for_game_devlopers/",
                "date": "2023-08-10"
            },
            {
                "tag": "Show Off",
                "title": "Hi, What do you think of the env I worked on? Posting as a gift ;)",
                "url": "https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExMXhlYTR6bWlhdDd6ZmdkdjVlMm9yaXY0M2pmeHB1cWptazVkcTcyaiZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/xWlClgxRUmLTHwq3oN/giphy.gif",
                "text": "",
                "link": "https://www.reddit.com/r/unrealengine/comments/15m34n0/hi_what_do_you_think_of_the_env_i_worked_on/",
                "date": "2023-08-10"
            },
            {
                "tag": "Tutorial",
                "title": "DataAssets are incredibly useful",
                "url": "https://www.reddit.com/r/unrealengine/comments/15jpvlc/dataassets_are_incredibly_useful/",
                "text": "I post this because I don't see this mentioned enough. Not only in reddit but also other resources:  \nUse DataAssets.  \nThey are a great tool of interaction between the editor and C++ without relying on BluePrints.  \nExample:  \nImagine you have a Character in your game, who can equip several different weapons. Now you want to show an overview of the stats (damage, recoil, etc.) of the weapon. How do you do it?  \nIf you just have a base Weapon actor and create a BluePrint out of it for each different weapon, you cannot read properties from it without spawning it, which isn't optimal.  \nYou can create a DataAsset for every weapon though. This DataAsset can include all necessary information that you need for displaying stats AND spawning the resulting actor afterwars (by TSubclassof&lt;AWhatever&gt;) and you can just read the information without spawning anything or whatever.  \nI hope that will save you some trouble.",
                "link": "https://www.reddit.com/r/unrealengine/comments/15jpvlc/dataassets_are_incredibly_useful/",
                "date": "2023-08-10"
            },
            {
                "tag": "Show Off",
                "title": "Finally managed to finish my first game",
                "url": "https://www.reddit.com/r/unrealengine/comments/15kpfy1/finally_managed_to_finish_my_first_game/",
                "text": "Hi,\n\nafter 4 long years of development and gettings tips off this sub and others on and off, I finally decided to release my steam page for my game \"Marine Glory\". Scheduled to release end of 2023.  \n[https://store.steampowered.com/app/2409000/Marine\\_Glory/](https://store.steampowered.com/app/2409000/Marine_Glory/)\n\nI'm a full-time developer, but nothing game related, so I worked on this mostly on weekends and sometimes in the evening after work.  \nI'm really glad this sub and others exist, because they're such a great tool for learning. I got into Unity before Unreal, and at first all the classes (Pawns, Characters etc.) instead of just Actors seemed really daunting, but if you get used to it, they give you awesome utility and really ease your development.   \n\n\nThe game is not released yet, but I added a playtest to the steam page, where you can just download and play the full game, with the exception of steam achievements.\n\nSo, if you found the time to test the game and give me feedback, I'd be super grateful.\n\nThank you very much!",
                "link": "https://www.reddit.com/r/unrealengine/comments/15kpfy1/finally_managed_to_finish_my_first_game/",
                "date": "2023-08-10"
            },
            {
                "tag": "Show Off",
                "title": "I made a Track editor of my lowpoly racing game",
                "url": "https://www.youtube.com/watch?v=V0laTeF4boY",
                "text": "",
                "link": "https://www.reddit.com/r/unrealengine/comments/15h2a0t/i_made_a_track_editor_of_my_lowpoly_racing_game/",
                "date": "2023-08-10"
            }
        ]
    },
    "golang": {
        "2023-08-10": [
            {
                "tag": null,
                "title": "Go 1.21.0 is released",
                "url": "https://www.reddit.com/r/golang/comments/15llcat/go_1210_is_released/",
                "text": "[Announcement](https://groups.google.com/g/golang-announce/c/Mk0Jar6hfhI)\n\n[Release Notes](https://go.dev/doc/go1.21)\n\n[Blog](https://go.dev/blog/go1.21)\n\n[Download](https://go.dev/dl/#go1.21.0)",
                "link": "https://www.reddit.com/r/golang/comments/15llcat/go_1210_is_released/",
                "date": "2023-08-10"
            },
            {
                "tag": null,
                "title": "Go 1.21 All you need to know",
                "url": "https://miro.com/app/board/uXjVMBkmPPQ=/",
                "text": "Go 1.21 is out! \ud83d\ude80\ud83c\udf89It comes with great features and many valuable improvements to the runtime.\n\nMy favorite:\nThe new (experimental) Web Assembly System Interface (#WASI) support.\n\nCheck out more at https://miro.com/app/board/uXjVMBkmPPQ=/",
                "link": "https://www.reddit.com/r/golang/comments/15m7p7d/go_121_all_you_need_to_know/",
                "date": "2023-08-10"
            },
            {
                "tag": "help",
                "title": "Learning Go deeply",
                "url": "https://www.reddit.com/r/golang/comments/15ihv29/learning_go_deeply/",
                "text": "Are there any resource to learn Go deeply? I want to be able to understand not just how to do stuff but how everything works inside. Learn more about the intrinsic details like how to optimize my code, how the garbage collector work, how to manage the memory... that kind of stuff.\n\nWhat is a good learning path to achieve a higher level of mastery?\n\nRight now I know how to build web services, cli apps, I lnow to work with go routines and channels. Etc...\n\nBut I want to keep learning more, I feel kind of stuck.",
                "link": "https://www.reddit.com/r/golang/comments/15ihv29/learning_go_deeply/",
                "date": "2023-08-10"
            },
            {
                "tag": null,
                "title": "Company migration to Go",
                "url": "https://www.reddit.com/r/golang/comments/15hztqt/company_migration_to_go/",
                "text": "Hello,\n\nI have been using Golang exclusively for the past 4.5 years for SaaS, cloud and cloud-native applications quite successfully both as a developer and technical lead.\n\nIn my previous company I have led the technical aspects of writing the product from scratch using Go pretty much vanilla (no web framework, only using gin, no ORM at all) and was very happy (and successful to be honest)\n\nI have recently started a new role in a company that wants to migrate from Java to Go (I was not advocating that. There\u2019s lots of legacy code there and they find it difficult to attract talent), and I was tasked to lead the migration effort and want to make sure I am on the same page with the industry and not inventing the wheel.\n\nMy plan is to continue what\u2019s been working successfully for me for the past 5 years almost:\nGo\nAWS with high reliance on managed services (lambda, eks, api gateway and authorizer, cognito/auth0)\nGin but decouple and abstract as much as possible\nNo ORM\nCode generation where possible (oapi-codegen, groc/twirp for RPC)\n\nI try to avoid frameworks as much as possible because I get lots of stuff such as caching, rate limiting and etc from my managed services (API gateway for example) and also want full control over my db queries and models.\n\nBut yet go-micro and other frameworks remain highly popular.\n\nWhat are your choices and thoughts? Yes, I know that keeping what\u2019s working is great but I\u2019m always open to improving my stack and tooling\n\nThanks,",
                "link": "https://www.reddit.com/r/golang/comments/15hztqt/company_migration_to_go/",
                "date": "2023-08-10"
            },
            {
                "tag": null,
                "title": "Cognitive load of GO vs other languages",
                "url": "https://www.reddit.com/r/golang/comments/15kpzqf/cognitive_load_of_go_vs_other_languages/",
                "text": "So I wrote an app a few weeks ago that had a frontend written in Alpine JS and PHP on the BE. I used PHP because I wanted something easy to deploy (typically use Ruby for web dev). I decided to port it to GO for fun because I did a bit of go before.\n\nIt took **3x as many lines as PHP! 3x as many. Crazy.** That's partly because you can't have 1 line if statements with my linter and because of all the error handling.\n\nBUT, what I noticed is that even though it's much more verbose the **cognitive load with GO is SO MUCH LOWER**.\n\nI love to code and have been doing it for 25+years but I realize that sometimes when I have hard features to code I sort treat it like a mission I have to go on. I know it's going to be stressful and unpleasant.\n\nWith GO however it all seems pretty easy. For one the fact that it's staticly typed is a lifesaver. I'm used to that with C++ and Java though, but **the way Fiber handles taking your POST JSON and sticking it into a struct is great**. You don't have to wonder \"wait, is this actually a string when I thought it was a number?\" That really mitigates a lot of the stress of building webapps. That communication layer between FE and BE can be a pain.\n\n**I feel like my mental CPU clock just stays at 15% instead of averaging 50% and spiking up to 100** frequently (sort of like GO vs Node on a server). I just can't get past that. Even though the language itself is nothing special. It doesn't even have ternaries, but I can always look at the code and it's basically as simple as it gets.\n\nIdk, **writing go I just feel a big weight has been lifted off of my shoulders**, I don't mind the stress of programming, I enjoy the fight but now I'm like \"huh, I'm really productive and I'm not stressed at all...\"\n\nAs I mentioned earlier I used PHP because it's easy to deploy. Well... **GO is not QUITE as easy to deploy as PHP**, you can't just stuff your files on a shared host BUT I've been deploying to a DO node by just FTPing in and dropping my self contained executable. That's really, really easy. Also, I use NGINX so I just make a nginx entry for it and there you go. Plus it takes so little ram that you can deploy like 10 go apps to one $5 vps.\n\nPlus when you need to look at the code of a package you use it's pretty easy to understand what's going on in most cases.\n\nI'm honestly surprised GO isn't more popular. Like it's not the cool kid. People are loving typescript (which is a nightmare to me personally) and want to use it everywhere but like to me it's not worth it.\n\n**And the best part, is that it gets amazing performance out of the box.** I tried Rust which is an enigma wrapped in a mystery inside a riddle (thanks WC). It's so painful to get working with it, and GO isn't as good as Rust in terms of performance but it's close enough and it's about 20x easier as a language.\n\nAnyway, just wanted to share that. I really like it.\n\n**Edit:** Also recompiling is a pain but the fact that so many errors are caught before or during compile makes up for it. With dynamic languages it's like \"Okay now it's reloaded... What did I break, lets see\"",
                "link": "https://www.reddit.com/r/golang/comments/15kpzqf/cognitive_load_of_go_vs_other_languages/",
                "date": "2023-08-10"
            }
        ]
    }
}